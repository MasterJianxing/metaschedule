2023-04-11 10:46:37 [INFO] [task_scheduler.cc:160] Initializing Task #5: "fused_nn_conv2d_add_nn_relu"
2023-04-11 10:46:37 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float16"], p1: T.Buffer[(T.int64(64), T.int64(3), T.int64(7), T.int64(7)), "float16"], p2: T.Buffer[(T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float16"], T_relu: T.Buffer[(T.int64(1), T.int64(64), T.int64(112), T.int64(112)), "float16"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([T.int64(1), T.int64(3), T.int64(230), T.int64(230)], dtype="float16")
        conv2d_nchw = T.alloc_buffer([T.int64(1), T.int64(64), T.int64(112), T.int64(112)], dtype="float16")
        T_add = T.alloc_buffer([T.int64(1), T.int64(64), T.int64(112), T.int64(112)], dtype="float16")
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(3), T.int64(230), T.int64(230)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(3), v_i3 - T.int64(3)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(3) <= v_i2 and v_i2 < T.int64(227) and T.int64(3) <= v_i3 and v_i3 < T.int64(227), p0[v_i0, v_i1, v_i2 - T.int64(3), v_i3 - T.int64(3)], T.float16(0), dtype="float16")
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(64), T.int64(112), T.int64(112), T.int64(3), T.int64(7), T.int64(7)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx], p1[v_ff, v_rc, v_ry, v_rx])
                T.writes(conv2d_nchw[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    conv2d_nchw[v_nn, v_ff, v_yy, v_xx] = T.float16(0)
                conv2d_nchw[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx] * p1[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(64), T.int64(112), T.int64(112)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(conv2d_nchw[v_ax0, v_ax1, v_ax2, v_ax3], p2[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = conv2d_nchw[v_ax0, v_ax1, v_ax2, v_ax3] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(64), T.int64(112), T.int64(112)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3], T.float16(0))
    

2023-04-11 10:46:37 [INFO] [multi_level_tiling_tensor_core.cc:212] Sketch 0: tensorizing with wmma_sync_16x16x16_f16f16f16_trans
2023-04-11 10:46:37 [INFO] [multi_level_tiling_tensor_core.cc:212] Sketch 1: tensorizing with wmma_sync_16x16x16_f16f16f16
2023-04-11 10:46:37 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-04-11 10:46:37 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float16"], p1: T.Buffer[(T.int64(64), T.int64(3), T.int64(7), T.int64(7)), "float16"], p2: T.Buffer[(T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float16"], T_relu: T.Buffer[(T.int64(1), T.int64(64), T.int64(112), T.int64(112)), "float16"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":16})
            conv2d_nchw_reindex_shared = T.alloc_buffer([T.int64(12544), T.int64(64)], dtype="float16", scope="shared")
            conv2d_nchw_reindex_shared_wmma_accumulator = T.alloc_buffer([T.int64(12544), T.int64(64)], dtype="float16", scope="wmma.accumulator")
            pad_temp_reindex_shared = T.alloc_buffer([T.int64(12544), T.int64(160)], dtype="float16", scope="shared")
            p1_reindex_shared = T.alloc_buffer([T.int64(160), T.int64(64)], dtype="float16", scope="shared")
            pad_temp_reindex_shared_wmma_matrix_a = T.alloc_buffer([T.int64(12544), T.int64(160)], dtype="float16", scope="wmma.matrix_a")
            p1_reindex_shared_wmma_matrix_b = T.alloc_buffer([T.int64(160), T.int64(64)], dtype="float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(T.int64(1), thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(T.int64(7), thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(T.int64(8), thread="threadIdx.y"):
                        for ax2_0_0 in T.serial(T.int64(2)):
                            for ax0_ax1_fused in T.serial(T.int64(143360)):
                                with T.block("pad_temp_reindex_shared"):
                                    v0 = T.axis.spatial(T.int64(12544), ax0_0_1_ax1_0_1_fused * T.int64(1792) + ax0_ax1_fused // T.int64(80))
                                    v1 = T.axis.spatial(T.int64(160), ax2_0_0 * T.int64(80) + ax0_ax1_fused % T.int64(80))
                                    T.reads(p0[v0 // T.int64(12544), v1 // T.int64(49), v0 // T.int64(112) * T.int64(2) + v1 % T.int64(49) // T.int64(7) - T.int64(3), v0 % T.int64(112) * T.int64(2) + v1 % T.int64(7) - T.int64(3)])
                                    T.writes(pad_temp_reindex_shared[v0, v1])
                                    T.block_attr({"buffer_dim_align":[[0, 0, 32, 8]], "meta_schedule.cooperative_fetch":8})
                                    pad_temp_reindex_shared[v0, v1] = T.if_then_else(v1 < T.int64(147), T.if_then_else(T.int64(3) <= v0 // T.int64(112) * T.int64(2) + v1 % T.int64(49) // T.int64(7) and v0 // T.int64(112) * T.int64(2) + v1 % T.int64(49) // T.int64(7) < T.int64(227) and T.int64(3) <= v0 % T.int64(112) * T.int64(2) + v1 % T.int64(7) and v0 % T.int64(112) * T.int64(2) + v1 % T.int64(7) < T.int64(227), p0[v0 // T.int64(12544), v1 // T.int64(49), v0 // T.int64(112) * T.int64(2) + v1 % T.int64(49) // T.int64(7) - T.int64(3), v0 % T.int64(112) * T.int64(2) + v1 % T.int64(7) - T.int64(3)], T.float16(0), dtype="float16"), T.float16(0), dtype="float16")
                            for ax0_ax1_fused in T.serial(T.int64(5120)):
                                with T.block("p1_reindex_shared"):
                                    v0 = T.axis.spatial(T.int64(160), ax2_0_0 * T.int64(80) + ax0_ax1_fused // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(64), ax0_ax1_fused % T.int64(64))
                                    T.reads(p1[v1, v0 // T.int64(49), v0 % T.int64(49) // T.int64(7), v0 % T.int64(7)])
                                    T.writes(p1_reindex_shared[v0, v1])
                                    T.block_attr({"buffer_dim_align":[[0, 0, 32, 8]], "meta_schedule.cooperative_fetch":8})
                                    p1_reindex_shared[v0, v1] = T.if_then_else(v0 < T.int64(147), p1[v1, v0 // T.int64(49), v0 % T.int64(49) // T.int64(7), v0 % T.int64(7)], T.float16(0), dtype="float16")
                            for ax2_0_1 in T.serial(T.int64(5)):
                                for ax0_0, ax1_0 in T.grid(T.int64(28), T.int64(1)):
                                    with T.block("pad_temp_reindex_shared_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(T.int64(784), ax0_0_1_ax1_0_1_fused * T.int64(112) + ax0_0_2_ax1_0_2_fused // T.int64(2) * T.int64(28) + ax0_0)
                                        v1_o = T.axis.spatial(T.int64(10), ax2_0_0 * T.int64(5) + ax2_0_1 + ax1_0)
                                        T.reads(pad_temp_reindex_shared[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.writes(pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.block_attr({"meta_schedule.auto_tensorize":"wmma_load_16x16x16_f16_a"})
                                        for ax0_1, ax1_1 in T.grid(T.int64(16), T.int64(16)):
                                            with T.block("pad_temp_reindex_shared_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(pad_temp_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                T.writes(pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] = pad_temp_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i]
                                for ax0_0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                                    with T.block("p1_reindex_shared_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(T.int64(10), ax2_0_0 * T.int64(5) + ax2_0_1 + ax0_0)
                                        v1_o = T.axis.spatial(T.int64(4), ax0_0_2_ax1_0_2_fused % T.int64(2) * T.int64(2) + ax1_0)
                                        T.reads(p1_reindex_shared[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.writes(p1_reindex_shared_wmma_matrix_b[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.block_attr({"meta_schedule.auto_tensorize":"wmma_load_16x16x16_f16_b"})
                                        for ax0_1, ax1_1 in T.grid(T.int64(16), T.int64(16)):
                                            with T.block("p1_reindex_shared_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(p1_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                T.writes(p1_reindex_shared_wmma_matrix_b[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                p1_reindex_shared_wmma_matrix_b[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] = p1_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(T.int64(28), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                                    with T.block("conv2d_nchw_o"):
                                        v0_o = T.axis.spatial(T.int64(784), ax0_0_1_ax1_0_1_fused * T.int64(112) + ax0_0_2_ax1_0_2_fused // T.int64(2) * T.int64(28) + ax0_0_3 + ax0_0_4)
                                        v1_o = T.axis.spatial(T.int64(4), ax0_0_2_ax1_0_2_fused % T.int64(2) * T.int64(2) + ax1_0_3 * T.int64(2) + ax1_0_4)
                                        v2_o = T.axis.reduce(T.int64(10), ax2_0_0 * T.int64(5) + ax2_0_1 + ax2_0_2)
                                        T.reads(pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v2_o * T.int64(16) : v2_o * T.int64(16) + T.int64(16)], p1_reindex_shared_wmma_matrix_b[v2_o * T.int64(16) : v2_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.writes(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.block_attr({"meta_schedule.auto_tensorize":"wmma_sync_16x16x16_f16f16f16", "meta_schedule.auto_tensorize_init":"wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "warp_execution":1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(T.int64(16), T.int64(16)):
                                                with T.block("conv2d_nchw_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i_init, v1_o * T.int64(16) + v1_i_init])
                                                    conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i_init, v1_o * T.int64(16) + v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(T.int64(16), T.int64(16), T.int64(16)):
                                            with T.block("conv2d_nchw"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i], pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) + v0_i, v2_o * T.int64(16) + v2_i], p1_reindex_shared_wmma_matrix_b[v2_o * T.int64(16) + v2_i, v1_o * T.int64(16) + v1_i])
                                                T.writes(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure":"SSSRRSRS"})
                                                conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] = conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] + pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) + v0_i, v2_o * T.int64(16) + v2_i] * p1_reindex_shared_wmma_matrix_b[v2_o * T.int64(16) + v2_i, v1_o * T.int64(16) + v1_i]
                        for ax0_0, ax1_0 in T.grid(T.int64(28), T.int64(2)):
                            with T.block("conv2d_nchw_reindex_shared_wmma.accumulator_o"):
                                v0_o = T.axis.spatial(T.int64(784), ax0_0_1_ax1_0_1_fused * T.int64(112) + ax0_0_2_ax1_0_2_fused // T.int64(2) * T.int64(28) + ax0_0)
                                v1_o = T.axis.spatial(T.int64(4), ax0_0_2_ax1_0_2_fused % T.int64(2) * T.int64(2) + ax1_0)
                                T.reads(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                T.writes(conv2d_nchw_reindex_shared[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                T.block_attr({"meta_schedule.auto_tensorize":"wmma_store_16x16x16_f16_shared"})
                                for ax0_1, ax1_1 in T.grid(T.int64(16), T.int64(16)):
                                    with T.block("conv2d_nchw_reindex_shared_wmma.accumulator"):
                                        v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                        T.reads(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                        T.writes(conv2d_nchw_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                        conv2d_nchw_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] = conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i]
                    for ax0_ax1_fused in T.serial(T.int64(114688)):
                        with T.block("conv2d_nchw_reindex_shared"):
                            v0 = T.axis.spatial(T.int64(12544), ax0_0_1_ax1_0_1_fused * T.int64(1792) + ax0_ax1_fused // T.int64(64))
                            v1 = T.axis.spatial(T.int64(64), ax0_ax1_fused % T.int64(64))
                            T.reads(conv2d_nchw_reindex_shared[v0, v1], p2[v0 // T.int64(12544), v1, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v0 // T.int64(12544), v1, v0 // T.int64(112), v0 % T.int64(112)])
                            T.block_attr({"meta_schedule.cooperative_fetch":2})
                            T_relu[v0 // T.int64(12544), v1, v0 // T.int64(112), v0 % T.int64(112)] = T.max(conv2d_nchw_reindex_shared[v0, v1] + p2[v0 // T.int64(12544), v1, T.int64(0), T.int64(0)], T.float16(0))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b5 = sch.reindex(block=b1, buffer=("write", 0))
b6 = sch.reindex(block=b1, buffer=("read", 0))
b7 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda v_nn, v_yy, v_xx, v_rc, v_ry, v_rx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), (((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx),), pad_value=None)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda v_ff, v_rc, v_ry, v_rx: ((((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx), v_ff,), pad_value=None)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda v_nn, v_ff, v_yy, v_xx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), v_ff,), pad_value=None)
sch.transform_block_layout(block=b5, index_map=lambda v_nn, v_ff, v_yy, v_xx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), v_ff,))
sch.transform_block_layout(block=b6, index_map=lambda v_nn, v_yy, v_xx, v_rc, v_ry, v_rx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), (((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx),))
sch.transform_block_layout(block=b7, index_map=lambda v_ff, v_rc, v_ry, v_rx: ((((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx), v_ff,))
sch.transform_block_layout(block=b1, index_map=lambda v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), v_ff, (((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx),))
sch.pad_einsum(block=b1, padding=[0, 0, 13])
l8, l9, l10 = sch.get_loops(block=b1)
l11, l12 = sch.split(loop=l10, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l9, factors=[None, 16], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l17, l18, l19, l20, l21, l22 = sch.get_loops(block=b1)
sch.reorder(l19, l21, l16, l14, l12)
b23 = sch.blockize(loop=l16, preserve_unit_iters=True)
sch.annotate(block_or_loop=b23, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16")
sch.annotate(block_or_loop=b23, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b23, ann_key="warp_execution", ann_val=1)
l24, l25, l26 = sch.get_loops(block=b23)
v27, v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l24, n=5, max_innermost_factor=4, decision=[1, 7, 4, 28, 1])
l32, l33, l34, l35, l36 = sch.split(loop=l24, factors=[v27, v28, v29, v30, v31], preserve_unit_iters=True)
v37, v38, v39, v40, v41 = sch.sample_perfect_tile(loop=l25, n=5, max_innermost_factor=4, decision=[1, 1, 2, 1, 2])
l42, l43, l44, l45, l46 = sch.split(loop=l25, factors=[v37, v38, v39, v40, v41], preserve_unit_iters=True)
v47, v48, v49 = sch.sample_perfect_tile(loop=l26, n=3, max_innermost_factor=4, decision=[2, 5, 1])
l50, l51, l52 = sch.split(loop=l26, factors=[v47, v48, v49], preserve_unit_iters=True)
sch.reorder(l32, l42, l33, l43, l34, l44, l50, l51, l35, l45, l52, l36, l46)
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="blockIdx.y")
l54 = sch.fuse(l33, l43, preserve_unit_iters=True)
sch.bind(loop=l54, thread_axis="blockIdx.x")
l55 = sch.fuse(l34, l44, preserve_unit_iters=True)
sch.bind(loop=l55, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b23, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b23, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b56 = sch.cache_write(block=b23, write_buffer_index=0, storage_scope="shared")
sch.reverse_compute_at(block=b56, loop=l54, preserve_unit_loops=True, index=-1)
b57 = sch.cache_write(block=b23, write_buffer_index=0, storage_scope="wmma.accumulator")
sch.reverse_compute_at(block=b57, loop=l55, preserve_unit_loops=True, index=-1)
l58, l59, l60, l61 = sch.get_loops(block=b56)
l62 = sch.fuse(l60, l61, preserve_unit_iters=True)
v63 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b56, ann_key="meta_schedule.cooperative_fetch", ann_val=v63)
sch.reverse_compute_inline(block=b5)
l64, l65, l66, l67, l68 = sch.get_loops(block=b57)
l69, l70 = sch.split(loop=l68, factors=[None, 16], preserve_unit_iters=True)
l71, l72 = sch.split(loop=l67, factors=[None, 16], preserve_unit_iters=True)
l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b57)
sch.reorder(l78, l72, l70)
b80 = sch.blockize(loop=l72, preserve_unit_iters=True)
sch.annotate(block_or_loop=b80, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared")
b81 = sch.cache_read(block=b23, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b23])
sch.compute_at(block=b81, loop=l50, preserve_unit_loops=True, index=-1)
l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b81)
l88 = sch.fuse(l86, l87, preserve_unit_iters=True)
v89 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b81, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b23, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b23])
sch.compute_at(block=b90, loop=l50, preserve_unit_loops=True, index=-1)
l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b90)
l97 = sch.fuse(l95, l96, preserve_unit_iters=True)
v98 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v98)
b99 = sch.cache_read(block=b23, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b99, loop=l51, preserve_unit_loops=True, index=-1)
l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b99)
l107, l108 = sch.split(loop=l106, factors=[None, 16], preserve_unit_iters=True)
l109, l110 = sch.split(loop=l105, factors=[None, 16], preserve_unit_iters=True)
l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b99)
sch.reorder(l118, l110, l108)
b120 = sch.blockize(loop=l110, preserve_unit_iters=True)
sch.annotate(block_or_loop=b120, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a")
b121 = sch.cache_read(block=b23, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b121, loop=l51, preserve_unit_loops=True, index=-1)
l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b121)
l129, l130 = sch.split(loop=l128, factors=[None, 16], preserve_unit_iters=True)
l131, l132 = sch.split(loop=l127, factors=[None, 16], preserve_unit_iters=True)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b121)
sch.reorder(l140, l132, l130)
b142 = sch.blockize(loop=l132, preserve_unit_iters=True)
sch.annotate(block_or_loop=b142, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b")
sch.compute_inline(block=b6)
sch.compute_inline(block=b7)
sch.storage_align(block=b81, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b90, buffer_index=0, axis=-2, factor=32, offset=8)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v143 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v143)
2023-04-11 10:46:37 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float16"], p1: T.Buffer[(T.int64(64), T.int64(3), T.int64(7), T.int64(7)), "float16"], p2: T.Buffer[(T.int64(1), T.int64(64), T.int64(1), T.int64(1)), "float16"], T_relu: T.Buffer[(T.int64(1), T.int64(64), T.int64(112), T.int64(112)), "float16"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            conv2d_nchw_reindex_shared = T.alloc_buffer([T.int64(12544), T.int64(64)], dtype="float16", scope="shared")
            conv2d_nchw_reindex_shared_wmma_accumulator = T.alloc_buffer([T.int64(12544), T.int64(64)], dtype="float16", scope="wmma.accumulator")
            pad_temp_reindex_shared = T.alloc_buffer([T.int64(12544), T.int64(160)], dtype="float16", scope="shared")
            p1_reindex_shared = T.alloc_buffer([T.int64(64), T.int64(160)], dtype="float16", scope="shared")
            pad_temp_reindex_shared_wmma_matrix_a = T.alloc_buffer([T.int64(12544), T.int64(160)], dtype="float16", scope="wmma.matrix_a")
            p1_reindex_shared_wmma_matrix_b = T.alloc_buffer([T.int64(64), T.int64(160)], dtype="float16", scope="wmma.matrix_b")
            for ax0_0_0_ax1_0_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.y"):
                for ax0_0_1_ax1_0_1_fused in T.thread_binding(T.int64(7), thread="blockIdx.x"):
                    for ax0_0_2_ax1_0_2_fused in T.thread_binding(T.int64(14), thread="threadIdx.y"):
                        for ax2_0_0 in T.serial(T.int64(1)):
                            for ax0_ax1_fused in T.serial(T.int64(35840)):
                                with T.block("pad_temp_reindex_shared"):
                                    v0 = T.axis.spatial(T.int64(12544), ax0_0_0_ax1_0_0_fused // T.int64(4) * T.int64(1568) + ax0_0_1_ax1_0_1_fused * T.int64(224) + ax0_ax1_fused // T.int64(160))
                                    v1 = T.axis.spatial(T.int64(160), ax0_ax1_fused % T.int64(160))
                                    T.reads(p0[v0 // T.int64(12544), v1 // T.int64(49), v0 // T.int64(112) * T.int64(2) + v1 % T.int64(49) // T.int64(7) - T.int64(3), v0 % T.int64(112) * T.int64(2) + v1 % T.int64(7) - T.int64(3)])
                                    T.writes(pad_temp_reindex_shared[v0, v1])
                                    T.block_attr({"buffer_dim_align":[[0, 0, 32, 8]], "meta_schedule.cooperative_fetch":8})
                                    pad_temp_reindex_shared[v0, v1] = T.if_then_else(v1 < T.int64(147), T.if_then_else(T.int64(3) <= v0 // T.int64(112) * T.int64(2) + v1 % T.int64(49) // T.int64(7) and v0 // T.int64(112) * T.int64(2) + v1 % T.int64(49) // T.int64(7) < T.int64(227) and T.int64(3) <= v0 % T.int64(112) * T.int64(2) + v1 % T.int64(7) and v0 % T.int64(112) * T.int64(2) + v1 % T.int64(7) < T.int64(227), p0[v0 // T.int64(12544), v1 // T.int64(49), v0 // T.int64(112) * T.int64(2) + v1 % T.int64(49) // T.int64(7) - T.int64(3), v0 % T.int64(112) * T.int64(2) + v1 % T.int64(7) - T.int64(3)], T.float16(0), dtype="float16"), T.float16(0), dtype="float16")
                            for ax0_ax1_fused in T.serial(T.int64(2560)):
                                with T.block("p1_reindex_shared"):
                                    v0 = T.axis.spatial(T.int64(64), ax0_0_0_ax1_0_0_fused % T.int64(4) * T.int64(16) + ax0_ax1_fused // T.int64(160))
                                    v1 = T.axis.spatial(T.int64(160), ax0_ax1_fused % T.int64(160))
                                    T.reads(p1[v0, v1 // T.int64(49), v1 % T.int64(49) // T.int64(7), v1 % T.int64(7)])
                                    T.writes(p1_reindex_shared[v0, v1])
                                    T.block_attr({"buffer_dim_align":[[0, 0, 32, 8]], "meta_schedule.cooperative_fetch":1})
                                    p1_reindex_shared[v0, v1] = T.if_then_else(v1 < T.int64(147), p1[v0, v1 // T.int64(49), v1 % T.int64(49) // T.int64(7), v1 % T.int64(7)], T.float16(0), dtype="float16")
                            for ax2_0_1 in T.serial(T.int64(5)):
                                for ax0_0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                                    with T.block("pad_temp_reindex_shared_wmma.matrix_a_o"):
                                        v0_o = T.axis.spatial(T.int64(784), ax0_0_0_ax1_0_0_fused // T.int64(4) * T.int64(98) + ax0_0_1_ax1_0_1_fused * T.int64(14) + ax0_0_2_ax1_0_2_fused + ax0_0)
                                        v1_o = T.axis.spatial(T.int64(10), ax2_0_1 * T.int64(2) + ax1_0)
                                        T.reads(pad_temp_reindex_shared[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.writes(pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.block_attr({"meta_schedule.auto_tensorize":"wmma_load_16x16x16_f16_a"})
                                        for ax0_1, ax1_1 in T.grid(T.int64(16), T.int64(16)):
                                            with T.block("pad_temp_reindex_shared_wmma.matrix_a"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(pad_temp_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                T.writes(pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] = pad_temp_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i]
                                for ax0_0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                                    with T.block("p1_reindex_shared_wmma.matrix_b_o"):
                                        v0_o = T.axis.spatial(T.int64(4), ax0_0_0_ax1_0_0_fused % T.int64(4) + ax0_0)
                                        v1_o = T.axis.spatial(T.int64(10), ax2_0_1 * T.int64(2) + ax1_0)
                                        T.reads(p1_reindex_shared[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.writes(p1_reindex_shared_wmma_matrix_b[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.block_attr({"meta_schedule.auto_tensorize":"wmma_load_16x16x16_f16_b_trans"})
                                        for ax0_1, ax1_1 in T.grid(T.int64(16), T.int64(16)):
                                            with T.block("p1_reindex_shared_wmma.matrix_b"):
                                                v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                                T.reads(p1_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                T.writes(p1_reindex_shared_wmma_matrix_b[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                p1_reindex_shared_wmma_matrix_b[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] = p1_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i]
                                for ax0_0_3, ax1_0_3, ax2_0_2, ax0_0_4, ax1_0_4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                                    with T.block("conv2d_nchw_o"):
                                        v0_o = T.axis.spatial(T.int64(784), ax0_0_0_ax1_0_0_fused // T.int64(4) * T.int64(98) + ax0_0_1_ax1_0_1_fused * T.int64(14) + ax0_0_2_ax1_0_2_fused + ax0_0_3 + ax0_0_4)
                                        v1_o = T.axis.spatial(T.int64(4), ax0_0_0_ax1_0_0_fused % T.int64(4) + ax1_0_3 + ax1_0_4)
                                        v2_o = T.axis.reduce(T.int64(10), ax2_0_0 * T.int64(10) + ax2_0_1 * T.int64(2) + ax2_0_2)
                                        T.reads(pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v2_o * T.int64(16) : v2_o * T.int64(16) + T.int64(16)], p1_reindex_shared_wmma_matrix_b[v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16), v2_o * T.int64(16) : v2_o * T.int64(16) + T.int64(16)])
                                        T.writes(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                        T.block_attr({"meta_schedule.auto_tensorize":"wmma_sync_16x16x16_f16f16f16_trans", "meta_schedule.auto_tensorize_init":"wmma_fill_16x16x16_f16", "meta_schedule.thread_extent_high_inclusive":1024, "meta_schedule.thread_extent_low_inclusive":32, "warp_execution":1})
                                        with T.init():
                                            for ax0_1, ax1_1 in T.grid(T.int64(16), T.int64(16)):
                                                with T.block("conv2d_nchw_init"):
                                                    v0_i_init, v1_i_init = T.axis.remap("SS", [ax0_1, ax1_1])
                                                    T.reads()
                                                    T.writes(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i_init, v1_o * T.int64(16) + v1_i_init])
                                                    conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i_init, v1_o * T.int64(16) + v1_i_init] = T.float16(0)
                                        for ax0_1, ax1_1, ax2_1 in T.grid(T.int64(16), T.int64(16), T.int64(16)):
                                            with T.block("conv2d_nchw"):
                                                v0_i, v1_i, v2_i = T.axis.remap("SSR", [ax0_1, ax1_1, ax2_1])
                                                T.reads(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i], pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) + v0_i, v2_o * T.int64(16) + v2_i], p1_reindex_shared_wmma_matrix_b[v1_o * T.int64(16) + v1_i, v2_o * T.int64(16) + v2_i])
                                                T.writes(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                                T.block_attr({"meta_schedule.tiling_structure":"SSSRRSRS"})
                                                conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] = conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] + pad_temp_reindex_shared_wmma_matrix_a[v0_o * T.int64(16) + v0_i, v2_o * T.int64(16) + v2_i] * p1_reindex_shared_wmma_matrix_b[v1_o * T.int64(16) + v1_i, v2_o * T.int64(16) + v2_i]
                        for ax0_0, ax1_0 in T.grid(T.int64(1), T.int64(1)):
                            with T.block("conv2d_nchw_reindex_shared_wmma.accumulator_o"):
                                v0_o = T.axis.spatial(T.int64(784), ax0_0_0_ax1_0_0_fused // T.int64(4) * T.int64(98) + ax0_0_1_ax1_0_1_fused * T.int64(14) + ax0_0_2_ax1_0_2_fused + ax0_0)
                                v1_o = T.axis.spatial(T.int64(4), ax0_0_0_ax1_0_0_fused % T.int64(4) + ax1_0)
                                T.reads(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                T.writes(conv2d_nchw_reindex_shared[v0_o * T.int64(16) : v0_o * T.int64(16) + T.int64(16), v1_o * T.int64(16) : v1_o * T.int64(16) + T.int64(16)])
                                T.block_attr({"meta_schedule.auto_tensorize":"wmma_store_16x16x16_f16_shared"})
                                for ax0_1, ax1_1 in T.grid(T.int64(16), T.int64(16)):
                                    with T.block("conv2d_nchw_reindex_shared_wmma.accumulator"):
                                        v0_i, v1_i = T.axis.remap("SS", [ax0_1, ax1_1])
                                        T.reads(conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                        T.writes(conv2d_nchw_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i])
                                        conv2d_nchw_reindex_shared[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i] = conv2d_nchw_reindex_shared_wmma_accumulator[v0_o * T.int64(16) + v0_i, v1_o * T.int64(16) + v1_i]
                    for ax0_ax1_fused in T.serial(T.int64(3584)):
                        with T.block("conv2d_nchw_reindex_shared"):
                            v0 = T.axis.spatial(T.int64(12544), ax0_0_0_ax1_0_0_fused // T.int64(4) * T.int64(1568) + ax0_0_1_ax1_0_1_fused * T.int64(224) + ax0_ax1_fused // T.int64(16))
                            v1 = T.axis.spatial(T.int64(64), ax0_0_0_ax1_0_0_fused % T.int64(4) * T.int64(16) + ax0_ax1_fused % T.int64(16))
                            T.reads(conv2d_nchw_reindex_shared[v0, v1], p2[v0 // T.int64(12544), v1, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v0 // T.int64(12544), v1, v0 // T.int64(112), v0 % T.int64(112)])
                            T.block_attr({"meta_schedule.cooperative_fetch":2})
                            T_relu[v0 // T.int64(12544), v1, v0 // T.int64(112), v0 % T.int64(112)] = T.max(conv2d_nchw_reindex_shared[v0, v1] + p2[v0 // T.int64(12544), v1, T.int64(0), T.int64(0)], T.float16(0))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_relu", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
b5 = sch.reindex(block=b1, buffer=("write", 0))
b6 = sch.reindex(block=b1, buffer=("read", 0))
b7 = sch.reindex(block=b1, buffer=("read", 1))
sch.transform_layout(block=b1, buffer=("read", 0), index_map=lambda v_nn, v_yy, v_xx, v_rc, v_ry, v_rx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), (((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx),), pad_value=None)
sch.transform_layout(block=b1, buffer=("read", 1), index_map=lambda v_ff, v_rc, v_ry, v_rx: (v_ff, (((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx),), pad_value=None)
sch.transform_layout(block=b1, buffer=("write", 0), index_map=lambda v_nn, v_ff, v_yy, v_xx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), v_ff,), pad_value=None)
sch.transform_block_layout(block=b5, index_map=lambda v_nn, v_ff, v_yy, v_xx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), v_ff,))
sch.transform_block_layout(block=b6, index_map=lambda v_nn, v_yy, v_xx, v_rc, v_ry, v_rx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), (((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx),))
sch.transform_block_layout(block=b7, index_map=lambda v_ff, v_rc, v_ry, v_rx: (v_ff, (((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx),))
sch.transform_block_layout(block=b1, index_map=lambda v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx: ((((v_nn*(int64)12544) + (v_yy*(int64)112)) + v_xx), v_ff, (((v_rc*(int64)49) + (v_ry*(int64)7)) + v_rx),))
sch.pad_einsum(block=b1, padding=[0, 0, 13])
l8, l9, l10 = sch.get_loops(block=b1)
l11, l12 = sch.split(loop=l10, factors=[None, 16], preserve_unit_iters=True)
l13, l14 = sch.split(loop=l9, factors=[None, 16], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l8, factors=[None, 16], preserve_unit_iters=True)
l17, l18, l19, l20, l21, l22 = sch.get_loops(block=b1)
sch.reorder(l19, l21, l16, l14, l12)
b23 = sch.blockize(loop=l16, preserve_unit_iters=True)
sch.annotate(block_or_loop=b23, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_sync_16x16x16_f16f16f16_trans")
sch.annotate(block_or_loop=b23, ann_key="meta_schedule.auto_tensorize_init", ann_val="wmma_fill_16x16x16_f16")
sch.annotate(block_or_loop=b23, ann_key="warp_execution", ann_val=1)
l24, l25, l26 = sch.get_loops(block=b23)
v27, v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l24, n=5, max_innermost_factor=4, decision=[8, 7, 14, 1, 1])
l32, l33, l34, l35, l36 = sch.split(loop=l24, factors=[v27, v28, v29, v30, v31], preserve_unit_iters=True)
v37, v38, v39, v40, v41 = sch.sample_perfect_tile(loop=l25, n=5, max_innermost_factor=4, decision=[4, 1, 1, 1, 1])
l42, l43, l44, l45, l46 = sch.split(loop=l25, factors=[v37, v38, v39, v40, v41], preserve_unit_iters=True)
v47, v48, v49 = sch.sample_perfect_tile(loop=l26, n=3, max_innermost_factor=4, decision=[1, 5, 2])
l50, l51, l52 = sch.split(loop=l26, factors=[v47, v48, v49], preserve_unit_iters=True)
sch.reorder(l32, l42, l33, l43, l34, l44, l50, l51, l35, l45, l52, l36, l46)
l53 = sch.fuse(l32, l42, preserve_unit_iters=True)
sch.bind(loop=l53, thread_axis="blockIdx.y")
l54 = sch.fuse(l33, l43, preserve_unit_iters=True)
sch.bind(loop=l54, thread_axis="blockIdx.x")
l55 = sch.fuse(l34, l44, preserve_unit_iters=True)
sch.bind(loop=l55, thread_axis="threadIdx.y")
sch.annotate(block_or_loop=b23, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b23, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b56 = sch.cache_write(block=b23, write_buffer_index=0, storage_scope="shared")
sch.reverse_compute_at(block=b56, loop=l54, preserve_unit_loops=True, index=-1)
b57 = sch.cache_write(block=b23, write_buffer_index=0, storage_scope="wmma.accumulator")
sch.reverse_compute_at(block=b57, loop=l55, preserve_unit_loops=True, index=-1)
l58, l59, l60, l61 = sch.get_loops(block=b56)
l62 = sch.fuse(l60, l61, preserve_unit_iters=True)
v63 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b56, ann_key="meta_schedule.cooperative_fetch", ann_val=v63)
sch.reverse_compute_inline(block=b5)
l64, l65, l66, l67, l68 = sch.get_loops(block=b57)
l69, l70 = sch.split(loop=l68, factors=[None, 16], preserve_unit_iters=True)
l71, l72 = sch.split(loop=l67, factors=[None, 16], preserve_unit_iters=True)
l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b57)
sch.reorder(l78, l72, l70)
b80 = sch.blockize(loop=l72, preserve_unit_iters=True)
sch.annotate(block_or_loop=b80, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_store_16x16x16_f16_shared")
b81 = sch.cache_read(block=b23, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b23])
sch.compute_at(block=b81, loop=l50, preserve_unit_loops=True, index=-1)
l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b81)
l88 = sch.fuse(l86, l87, preserve_unit_iters=True)
v89 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b81, ann_key="meta_schedule.cooperative_fetch", ann_val=v89)
b90 = sch.cache_read(block=b23, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b23])
sch.compute_at(block=b90, loop=l50, preserve_unit_loops=True, index=-1)
l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b90)
l97 = sch.fuse(l95, l96, preserve_unit_iters=True)
v98 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b90, ann_key="meta_schedule.cooperative_fetch", ann_val=v98)
b99 = sch.cache_read(block=b23, read_buffer_index=0, storage_scope="wmma.matrix_a")
sch.compute_at(block=b99, loop=l51, preserve_unit_loops=True, index=-1)
l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b99)
l107, l108 = sch.split(loop=l106, factors=[None, 16], preserve_unit_iters=True)
l109, l110 = sch.split(loop=l105, factors=[None, 16], preserve_unit_iters=True)
l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b99)
sch.reorder(l118, l110, l108)
b120 = sch.blockize(loop=l110, preserve_unit_iters=True)
sch.annotate(block_or_loop=b120, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_a")
b121 = sch.cache_read(block=b23, read_buffer_index=1, storage_scope="wmma.matrix_b")
sch.compute_at(block=b121, loop=l51, preserve_unit_loops=True, index=-1)
l122, l123, l124, l125, l126, l127, l128 = sch.get_loops(block=b121)
l129, l130 = sch.split(loop=l128, factors=[None, 16], preserve_unit_iters=True)
l131, l132 = sch.split(loop=l127, factors=[None, 16], preserve_unit_iters=True)
l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b121)
sch.reorder(l140, l132, l130)
b142 = sch.blockize(loop=l132, preserve_unit_iters=True)
sch.annotate(block_or_loop=b142, ann_key="meta_schedule.auto_tensorize", ann_val="wmma_load_16x16x16_f16_b_trans")
sch.compute_inline(block=b6)
sch.compute_inline(block=b7)
sch.storage_align(block=b81, buffer_index=0, axis=-2, factor=32, offset=8)
sch.storage_align(block=b90, buffer_index=0, axis=-2, factor=32, offset=8)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v143 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v143)
